# OpenAI API Key (Required for OpenAI models)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4

# Ollama Configuration (Optional, for local models)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=ollama/llama3

# AWS Bedrock Configuration (Optional, for AWS Bedrock)
AWS_ACCESS_KEY_ID=your_aws_access_key_id
AWS_SECRET_ACCESS_KEY=your_aws_secret_access_key
AWS_DEFAULT_REGION=us-east-1
BEDROCK_MODEL=anthropic.claude-3-sonnet-20240229-v1:0

# AWS Credentials (Optional, for AWS integrations)
# AWS_ACCESS_KEY_ID=your_aws_access_key_id
# AWS_SECRET_ACCESS_KEY=your_aws_secret_access_key
# AWS_DEFAULT_REGION=us-east-1

# Database Credentials (Optional, for database queries)
DB_HOST=your_db_host
DB_PORT=5432
DB_NAME=your_db_name
DB_USER=your_db_user
DB_PASSWORD=your_db_password

# Monitoring Service Credentials (Optional)
PROMETHEUS_URL=http://prometheus:9090
LOKI_URL=http://loki:3100
JAEGER_URL=http://jaeger:16686

# Document Storage (Optional)
CONFLUENCE_API_TOKEN=your_confluence_api_token
CONFLUENCE_URL=https://your-domain.atlassian.net/wiki

# LLM Configuration
# Choose your LLM provider - each has its own model and credential requirements
# Options: openai, ollama, bedrock, anthropic
LLM_PROVIDER=openai

# Temperature for LLM responses (0.0 to 1.0, lower is more deterministic)
TEMPERATURE=0.2

# Debugging settings
LOG_LEVEL=INFO 