# OpenAI API Key (Required for OpenAI models)
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4

# Ollama Configuration (Optional, for local models)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=ollama/llama3

# AWS Bedrock Configuration (Optional, for AWS Bedrock)
AWS_ACCESS_KEY_ID=your_aws_access_key_id
AWS_SECRET_ACCESS_KEY=your_aws_secret_access_key
AWS_DEFAULT_REGION=us-east-1
BEDROCK_MODEL=anthropic.claude-3-sonnet-20240229-v1:0

# Snowflake Cortex AI Configuration (Optional, for Snowflake Cortex)
SNOWFLAKE_ACCOUNT=your_snowflake_account_id
SNOWFLAKE_USER=your_snowflake_username
SNOWFLAKE_PASSWORD=your_snowflake_password
SNOWFLAKE_DATABASE=CORTEX_DB
SNOWFLAKE_SCHEMA=CORTEX_SCHEMA
SNOWFLAKE_WAREHOUSE=CORTEX_WH
SNOWFLAKE_ROLE=CORTEX_ROLE
SNOWFLAKE_MODEL=llama-3-08-70b-instruct

# AWS Credentials (Optional, for AWS integrations)
# AWS_ACCESS_KEY_ID=your_aws_access_key_id
# AWS_SECRET_ACCESS_KEY=your_aws_secret_access_key
# AWS_DEFAULT_REGION=us-east-1

# Database Credentials (Optional, for database queries)
DB_HOST=your_db_host
DB_PORT=5432
DB_NAME=your_db_name
DB_USER=your_db_user
DB_PASSWORD=your_db_password

# Monitoring Service Credentials (Optional)
PROMETHEUS_URL=http://prometheus:9090
LOKI_URL=http://localhost:3100
JAEGER_URL=http://jaeger:16686

# Document Storage (Optional)
CONFLUENCE_API_TOKEN=your_confluence_api_token
CONFLUENCE_URL=https://your-domain.atlassian.net/wiki

# LLM Configuration
# Choose your LLM provider - each has its own model and credential requirements
# Options: openai, ollama, bedrock, anthropic, snowflake, cortex
LLM_PROVIDER=openai

# Temperature for LLM responses (0.0 to 1.0, lower is more deterministic)
TEMPERATURE=0.2

# Debugging settings
LOG_LEVEL=INFO
LOG_FORMAT=json

# Application Configuration
DEBUG_MODE=false
MAX_RETRIES=3
TIMEOUT_SECONDS=30

# Slack Configuration
SLACK_APP_TOKEN=xapp-1-...
SLACK_BOT_TOKEN=xoxb-... 